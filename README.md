# E-commerce Search Algorithm Comparison Project

A comprehensive framework for comparing search algorithms (Keyword Matching vs TF-IDF) using real e-commerce and social media data.

## Quick Start

### 1. Installation
```bash
git clone <repository-url>
cd comp5112_gr7_project
python -m venv .venv
source .venv/bin/activate  # On Windows: .venv\Scripts\activate
pip install -r requirements.txt
```

## Local Setup

### 1. Database Initialization
The database is not included in the repository. Initialize it locally:

```bash
# Create database and tables
python scripts/utilities/database_initializer.py
```

### 2. Collect Real Data
```bash
# Collect from Shopify stores (no API key needed)
python scripts/data_collection/ecommerce_api_collector.py

# Collect social media data (requires API keys)
python scripts/data_collection/social_media_scraper.py
```

### 3. Environment Configuration
Copy the template and add your credentials:

```bash
cp env.template .env
# Edit .env with your API keys
```

**Important**: Never commit the `.env` file or `data/*.db` files to the repository.

### 4. Run the Application

#### Option A: Quick Start (Recommended)
```bash
# Use the startup script
./scripts/web/start_web.sh
```

#### Option B: Manual Start
```bash
# Development mode
python scripts/web/run_web.py

# Or using Flask CLI
export FLASK_APP=scripts/web/run_web.py
export FLASK_ENV=development
flask run --host=127.0.0.1 --port=5000
```

#### Option C: Production Mode
```bash
# Using Gunicorn (install: pip install gunicorn)
gunicorn -w 4 -b 127.0.0.1:5000 scripts.web.wsgi:application

# Using Waitress (install: pip install waitress)
waitress-serve --host=127.0.0.1 --port=5000 scripts.web.wsgi:application
```

**Then open http://127.0.0.1:5000 in your browser**

## ğŸ“ Project Structure

```
comp5112_gr7_project/
â”œâ”€â”€ data/                          # Data storage
â”‚   â””â”€â”€ ecommerce_research.db         # Main SQLite database
â”‚
â”œâ”€â”€ scripts/                       # Scripts organized by purpose
â”‚   â”œâ”€â”€ data_collection/              # Data collection scripts
â”‚   â”‚   â”œâ”€â”€ social_media_scraper.py
â”‚   â”‚   â””â”€â”€ ecommerce_api_collector.py
â”‚   â”œâ”€â”€ utilities/                    # Utility scripts
â”‚   â”‚   â””â”€â”€ database_initializer.py
â”‚   â””â”€â”€ web/                          # Web application scripts
â”‚       â”œâ”€â”€ run_web.py                # Development server entry point
â”‚       â”œâ”€â”€ wsgi.py                   # Production WSGI entry point
â”‚       â”œâ”€â”€ start_web.sh              # Automated startup script
â”‚       â””â”€â”€ start_web_simple.sh       # Simple startup script
â”‚
â”œâ”€â”€ src/ecommerce_search/          # Core application code
â”‚   â”œâ”€â”€ algorithms/                   # Search algorithms
â”‚   â”‚   â”œâ”€â”€ keyword_matching.py
â”‚   â”‚   â””â”€â”€ tfidf_search.py
â”‚   â”œâ”€â”€ database/                     # Database management
â”‚   â”‚   â”œâ”€â”€ db_manager.py
â”‚   â”‚   â””â”€â”€ models.py
â”‚   â”œâ”€â”€ evaluation/                   # Evaluation metrics
â”‚   â”‚   â”œâ”€â”€ comparison.py
â”‚   â”‚   â”œâ”€â”€ metrics.py
â”‚   â”‚   â””â”€â”€ algorithm_comparison.py
â”‚   â”œâ”€â”€ utils/                        # Utilities
â”‚   â”‚   â”œâ”€â”€ product_extractor.py
â”‚   â”‚   â”œâ”€â”€ base_scraper.py
â”‚   â”‚   â””â”€â”€ database_operations.py
â”‚   â”œâ”€â”€ web/                          # Web interface
â”‚   â”‚   â”œâ”€â”€ app.py
â”‚   â”‚   â”œâ”€â”€ routes.py
â”‚   â”‚   â”œâ”€â”€ static/
â”‚   â”‚   â””â”€â”€ templates/
â”‚   â””â”€â”€ cli.py
â”‚
â””â”€â”€ ğŸ“š docs/                          # Documentation
    â”œâ”€â”€ PROJECT_SUMMARY.md
    â”œâ”€â”€ USAGE_GUIDE.md
    â”œâ”€â”€ PRESENTATION_OUTLINE.md
    â””â”€â”€ RESEARCH_METHODOLOGY.md
```

## Key Features

### Search Algorithms
- **Keyword Matching**: Exact and partial keyword matching with configurable weights
- **TF-IDF**: Term Frequency-Inverse Document Frequency with vector similarity

### Evaluation Metrics
- Precision@K, Recall@K, F1@K
- NDCG@K (Normalized Discounted Cumulative Gain)
- MAP (Mean Average Precision)
- MRR (Mean Reciprocal Rank)

### Data Sources
- **Real API Data**: 200+ Shopify stores (43,226 products)
- **Social Media Data**: Reddit posts (9,000+ posts) with product discussions
- **Database Storage**: SQLite database for scalable data management

### User Interfaces
- **Web Application**: Modern browser-based interface
- **Command Line**: Programmatic access and automation
- **Python API**: Library for integration with other projects

## Data Collection

### Real API Data
```bash
python scripts/data_collection/collect_real_ecommerce.py

```

### Social Media Data
```bash
# Reddit and Twitter (requires API keys)
python scripts/data_collection/real_social_media_scraper.py
```

## Analysis and Testing

### Extract Product Information
```bash
# Extract product info from social media posts
python scripts/analysis/extract_product_info.py --update --limit 1000
```

### Run Algorithm Comparison
```bash
# Compare algorithms on different datasets
python scripts/analysis/compare_datasets.py
```

### Test Algorithms
```bash
# Simple algorithm comparison
python scripts/testing/simple_algorithm_comparison.py
```

## ğŸŒ Web Interface

The web interface provides:
- **Data Management**: Load products from database
- **Algorithm Comparison**: Run side-by-side algorithm comparisons
- **Interactive Search**: Test search queries in real-time
- **Performance Metrics**: View detailed evaluation results

Access at: **http://localhost:5000**

## ğŸ“š Documentation

- **[Complete Setup and Usage Guide](docs/USAGE_GUIDE.md)** - Detailed setup and usage instructions
- **[Research Methodology](docs/RESEARCH_METHODOLOGY.md)** - Academic research approach
- **[Project Summary](docs/PROJECT_SUMMARY.md)** - Comprehensive project overview
- **[Presentation Outline](docs/PRESENTATION_OUTLINE.md)** - PowerPoint presentation structure

## Configuration

### Environment Variables
Create a `.env` file with your configuration:

```bash
# Copy the template
cp env.template .env

# Edit with your settings
nano .env
```

Key variables:
- `DATABASE_URL`: Database connection string
- `SECRET_KEY`: Web application secret key
- `LOG_LEVEL`: Logging level (DEBUG, INFO, WARNING, ERROR)

### API Keys (Optional)
For real data collection, you'll need API keys:
- **Reddit**: https://www.reddit.com/prefs/apps
- **Twitter**: https://developer.twitter.com/

## ğŸ§ª Testing

```bash
# Check code quality
flake8 src/
```

## Troubleshooting

### Common Issues

1. **Database not found**: Run `python scripts/utilities/database_initializer.py`
2. **No data**: Run the data collection scripts to gather real data
3. **Import errors**: Ensure virtual environment is activated
4. **Port already in use**: Change port in web app configuration

### Getting Help

- Check the logs in `logs/` directory
- Check code quality: `flake8 src/`

## ğŸ“ˆ Research Applications

This system is designed for:
- **Academic Research**: Algorithm comparison studies
- **Industry Applications**: E-commerce search optimization
- **Educational Purposes**: Learning about search algorithms
- **Benchmarking**: Performance evaluation frameworks

## ğŸ—ï¸ Technical Specifications

- **Python 3.8+**: Modern Python features
- **Flask**: Web application framework
- **SQLAlchemy**: Database ORM
- **scikit-learn**: Machine learning algorithms

## ğŸ“„ License

MIT License - see LICENSE file for details.

## ğŸ‘¥ Authors

COMP5112 Group 7 - E-commerce Search Algorithm Comparison Project